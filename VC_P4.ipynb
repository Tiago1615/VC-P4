{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Python>=3.10 is required, but Python==3.9.20 is currently installed \n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import math \n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.20 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.14  Python-3.9.20 torch-2.4.1+cpu CPU (Intel Core(TM) i5-10300H 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=datasets/data.yaml, epochs=40, time=None, patience=100, batch=4, imgsz=416, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\santu\\OneDrive\\Escritorio\\Documentos ULPGC\\VC\\P4\\VC-P4\\datasets\\train\\labels... 178 images, 1 backgrounds, 0 corrupt: 100%|██████████| 178/178 [00:00<00:00, 1618.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\santu\\OneDrive\\Escritorio\\Documentos ULPGC\\VC\\P4\\VC-P4\\datasets\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\santu\\OneDrive\\Escritorio\\Documentos ULPGC\\VC\\P4\\VC-P4\\datasets\\valid\\labels... 59 images, 0 backgrounds, 0 corrupt: 100%|██████████| 59/59 [00:00<00:00, 1787.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\santu\\OneDrive\\Escritorio\\Documentos ULPGC\\VC\\P4\\VC-P4\\datasets\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40         0G      1.336      3.043      1.169          3        416: 100%|██████████| 45/45 [00:22<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90    0.00339      0.667      0.228      0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40         0G      1.411      2.131      1.193          2        416: 100%|██████████| 45/45 [00:21<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.452      0.178      0.212      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40         0G      1.483      2.121      1.202          3        416: 100%|██████████| 45/45 [00:21<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.731      0.544      0.582      0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40         0G      1.538      1.883      1.242          4        416: 100%|██████████| 45/45 [00:21<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.585      0.422      0.372      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40         0G      1.489      1.969      1.229          2        416: 100%|██████████| 45/45 [00:21<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.66      0.475      0.527      0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40         0G      1.585      1.894      1.231          6        416: 100%|██████████| 45/45 [00:22<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.657      0.522      0.559      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40         0G      1.526      1.872      1.282          4        416: 100%|██████████| 45/45 [00:21<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.67      0.578      0.569      0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40         0G      1.487      1.788      1.226          7        416: 100%|██████████| 45/45 [00:21<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.759        0.6       0.67      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40         0G      1.415      1.692      1.186          2        416: 100%|██████████| 45/45 [00:21<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.755      0.544      0.591      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40         0G      1.439      1.569      1.199          3        416: 100%|██████████| 45/45 [00:21<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.713      0.467      0.524      0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40         0G      1.446      1.525      1.206          5        416: 100%|██████████| 45/45 [00:21<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.779      0.625      0.723      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40         0G      1.387      1.408      1.185          3        416: 100%|██████████| 45/45 [00:25<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.849      0.644       0.73      0.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40         0G      1.336      1.498      1.172          6        416: 100%|██████████| 45/45 [00:23<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.802      0.656      0.721      0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40         0G      1.396      1.504       1.19          4        416: 100%|██████████| 45/45 [00:22<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.792      0.678      0.705      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40         0G      1.342      1.361      1.163          8        416: 100%|██████████| 45/45 [00:22<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.751      0.669      0.677      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40         0G      1.324       1.28      1.167          2        416: 100%|██████████| 45/45 [00:22<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.812      0.626      0.688        0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40         0G      1.289      1.242      1.142          3        416: 100%|██████████| 45/45 [00:22<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.85      0.632      0.717      0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40         0G      1.263      1.265      1.111          5        416: 100%|██████████| 45/45 [00:24<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.835      0.744      0.805      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40         0G       1.31      1.276      1.148          5        416: 100%|██████████| 45/45 [00:25<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.813      0.722      0.804      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40         0G      1.261      1.193      1.123          9        416: 100%|██████████| 45/45 [00:21<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.852      0.722      0.788      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40         0G      1.318      1.203      1.121          4        416: 100%|██████████| 45/45 [00:21<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.814      0.679      0.739      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40         0G      1.273      1.085      1.093          7        416: 100%|██████████| 45/45 [00:21<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.87      0.689      0.789      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40         0G      1.187      1.108       1.12          3        416: 100%|██████████| 45/45 [00:21<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.818      0.722      0.777      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40         0G      1.197      1.097      1.102          3        416: 100%|██████████| 45/45 [00:21<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.841      0.689      0.774       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40         0G      1.239       1.12      1.118          5        416: 100%|██████████| 45/45 [00:21<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.914      0.711      0.796      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40         0G      1.213      1.074      1.094          8        416: 100%|██████████| 45/45 [00:21<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.876      0.705      0.805       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40         0G      1.179      1.026      1.066          6        416: 100%|██████████| 45/45 [00:21<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.842      0.733      0.798      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40         0G      1.206      1.025      1.086          4        416: 100%|██████████| 45/45 [00:21<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.769      0.744      0.784       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40         0G      1.208      1.033       1.07          1        416: 100%|██████████| 45/45 [00:21<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.894      0.656      0.741      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40         0G      1.194      1.022      1.087          4        416: 100%|██████████| 45/45 [00:21<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.864      0.689      0.781        0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40         0G      1.192     0.9919      1.068          7        416: 100%|██████████| 45/45 [00:20<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.953      0.678      0.793      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40         0G      1.148      0.971      1.038          4        416: 100%|██████████| 45/45 [00:21<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.96      0.667      0.796      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40         0G      1.067     0.8832     0.9854          2        416: 100%|██████████| 45/45 [00:20<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.86      0.711      0.797      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40         0G      1.095     0.8721      1.001          2        416: 100%|██████████| 45/45 [00:21<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.914      0.667      0.806      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40         0G      1.066       0.88      0.984          2        416: 100%|██████████| 45/45 [00:21<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.855      0.711       0.81      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40         0G      1.065     0.8565      1.031          2        416: 100%|██████████| 45/45 [00:21<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90        0.9      0.722      0.822      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40         0G      1.048     0.8514     0.9808          3        416: 100%|██████████| 45/45 [00:21<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.861      0.744      0.823      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40         0G      1.051       0.83     0.9936          3        416: 100%|██████████| 45/45 [00:21<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.906      0.733      0.824      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40         0G       1.05     0.8412     0.9801          5        416: 100%|██████████| 45/45 [00:21<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.91      0.744      0.829      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40         0G      1.014     0.7961     0.9561          3        416: 100%|██████████| 45/45 [00:24<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90      0.899      0.744      0.816      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 epochs completed in 0.281 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.14  Python-3.9.20 torch-2.4.1+cpu CPU (Intel Core(TM) i5-10300H 2.50GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.91      0.744      0.829      0.543\n",
      "Speed: 0.7ms preprocess, 33.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Ultralytics 8.3.14  Python-3.9.20 torch-2.4.1+cpu CPU (Intel Core(TM) i5-10300H 2.50GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\santu\\OneDrive\\Escritorio\\Documentos ULPGC\\VC\\P4\\VC-P4\\datasets\\valid\\labels.cache... 59 images, 0 backgrounds, 0 corrupt: 100%|██████████| 59/59 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         90       0.91      0.744      0.829      0.543\n",
      "Speed: 0.7ms preprocess, 33.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train22\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_car_plates = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model_car_plates.train(data=\"datasets/data.yaml\", epochs=40, imgsz=416, batch=4, device=\"cpu\")\n",
    "\n",
    "results = model_car_plates.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 1 bus, 64.4ms\n",
      "\n",
      "0: 352x416 1 matriculas, 34.2ms\n",
      "Speed: 2.0ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 48.2ms\n",
      "\n",
      "0: 352x416 (no detections), 36.2ms\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.94\n",
      "Clase --> bus\n",
      "\n",
      "0: 352x416 3 matriculass, 35.6ms\n",
      "Speed: 2.0ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 53.6ms\n",
      "\n",
      "0: 352x416 (no detections), 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.94\n",
      "Clase --> bus\n",
      "\n",
      "0: 352x416 4 matriculass, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 53.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 49.6ms\n",
      "\n",
      "0: 352x416 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.9\n",
      "Clase --> bus\n",
      "\n",
      "0: 320x416 4 matriculass, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 51.6ms\n",
      "\n",
      "0: 352x416 (no detections), 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.93\n",
      "Clase --> bus\n",
      "\n",
      "0: 320x416 3 matriculass, 34.0ms\n",
      "Speed: 1.0ms preprocess, 34.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 51.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 46.5ms\n",
      "\n",
      "0: 352x416 (no detections), 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.94\n",
      "Clase --> bus\n",
      "\n",
      "0: 352x416 3 matriculass, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 48.2ms\n",
      "\n",
      "0: 352x416 (no detections), 35.6ms\n",
      "Speed: 0.5ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.94\n",
      "Clase --> bus\n",
      "\n",
      "0: 352x416 1 matriculas, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 48.1ms\n",
      "\n",
      "0: 352x416 (no detections), 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.94\n",
      "Clase --> bus\n",
      "\n",
      "0: 320x416 4 matriculass, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 43.1ms\n",
      "\n",
      "0: 352x416 1 matriculas, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 3 matriculass, 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 38.6ms\n",
      "\n",
      "0: 352x416 (no detections), 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.95\n",
      "Clase --> bus\n",
      "\n",
      "0: 320x416 4 matriculass, 30.2ms\n",
      "Speed: 0.0ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 41.6ms\n",
      "\n",
      "0: 352x416 1 matriculas, 31.6ms\n",
      "Speed: 2.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 42.6ms\n",
      "\n",
      "0: 352x416 1 matriculas, 30.7ms\n",
      "Speed: 1.5ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.25\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 30.2ms\n",
      "Speed: 0.0ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 45.1ms\n",
      "\n",
      "0: 352x416 (no detections), 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.94\n",
      "Clase --> bus\n",
      "\n",
      "0: 320x416 3 matriculass, 32.1ms\n",
      "Speed: 0.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 44.2ms\n",
      "\n",
      "0: 352x416 1 matriculas, 33.1ms\n",
      "Speed: 2.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 2 matriculass, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 46.1ms\n",
      "\n",
      "0: 352x416 1 matriculas, 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 2 matriculass, 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 45.8ms\n",
      "\n",
      "0: 352x416 1 matriculas, 34.1ms\n",
      "Speed: 1.5ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 2 matriculass, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 45.8ms\n",
      "\n",
      "0: 352x416 1 matriculas, 34.1ms\n",
      "Speed: 1.5ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 3 matriculass, 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 44.7ms\n",
      "\n",
      "0: 384x416 1 matriculas, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 2 matriculass, 35.2ms\n",
      "Speed: 0.0ms preprocess, 35.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 48.1ms\n",
      "\n",
      "0: 384x416 (no detections), 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.92\n",
      "Clase --> bus\n",
      "\n",
      "0: 352x416 2 matriculass, 34.9ms\n",
      "Speed: 0.0ms preprocess, 34.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 44.1ms\n",
      "\n",
      "0: 384x416 2 matriculass, 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 3 matriculass, 35.1ms\n",
      "Speed: 1.5ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 45.7ms\n",
      "\n",
      "0: 384x416 (no detections), 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.92\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x416 3 matriculass, 36.1ms\n",
      "Speed: 0.0ms preprocess, 36.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 47.6ms\n",
      "\n",
      "0: 384x416 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.92\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x416 2 matriculass, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 45.6ms\n",
      "\n",
      "0: 384x416 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.92\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x416 3 matriculass, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 46.9ms\n",
      "\n",
      "0: 384x416 (no detections), 34.6ms\n",
      "Speed: 1.5ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.91\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x416 1 matriculas, 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 46.9ms\n",
      "\n",
      "0: 384x416 1 matriculas, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 48.1ms\n",
      "\n",
      "0: 416x416 1 matriculas, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 36.2ms\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 43.3ms\n",
      "\n",
      "0: 416x416 1 matriculas, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 45.6ms\n",
      "\n",
      "0: 416x416 (no detections), 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.9\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x416 2 matriculass, 39.1ms\n",
      "Speed: 1.8ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 42.1ms\n",
      "\n",
      "0: 416x416 1 matriculas, 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 40.7ms\n",
      "\n",
      "0: 416x416 (no detections), 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.9\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x416 3 matriculass, 36.2ms\n",
      "Speed: 2.0ms preprocess, 36.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 40.2ms\n",
      "\n",
      "0: 416x416 1 matriculas, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 33.8ms\n",
      "Speed: 1.0ms preprocess, 33.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 44.6ms\n",
      "\n",
      "0: 416x416 1 matriculas, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 46.2ms\n",
      "\n",
      "0: 416x416 2 matriculass, 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 50.6ms\n",
      "\n",
      "0: 416x416 (no detections), 38.6ms\n",
      "Speed: 2.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.93\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x416 1 matriculas, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 50.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 46.6ms\n",
      "\n",
      "0: 416x416 (no detections), 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.93\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x416 2 matriculass, 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 47.1ms\n",
      "\n",
      "0: 416x416 (no detections), 47.2ms\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.92\n",
      "Clase --> bus\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 43.1ms\n",
      "\n",
      "0: 416x416 1 matriculas, 38.8ms\n",
      "Speed: 1.0ms preprocess, 38.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 1 matriculas, 48.5ms\n",
      "Speed: 1.5ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.3ms\n",
      "\n",
      "0: 416x416 1 matriculas, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 46.1ms\n",
      "\n",
      "0: 416x416 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.91\n",
      "Clase --> bus\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 47.4ms\n",
      "\n",
      "0: 416x416 (no detections), 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.91\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.3ms\n",
      "\n",
      "0: 416x416 2 matriculass, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.9ms\n",
      "\n",
      "0: 416x416 (no detections), 37.0ms\n",
      "Speed: 2.5ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.93\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.1ms\n",
      "\n",
      "0: 416x416 1 matriculas, 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 46.2ms\n",
      "\n",
      "0: 416x416 1 matriculas, 39.5ms\n",
      "Speed: 0.5ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.2ms\n",
      "\n",
      "0: 416x416 2 matriculass, 36.4ms\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 45.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.6ms\n",
      "\n",
      "0: 416x416 1 matriculas, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.3ms\n",
      "\n",
      "0: 384x416 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.93\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 43.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.1ms\n",
      "\n",
      "0: 416x416 (no detections), 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.92\n",
      "Clase --> bus\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.8ms\n",
      "\n",
      "0: 416x416 1 matriculas, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.6ms\n",
      "\n",
      "0: 384x416 1 matriculas, 35.5ms\n",
      "Speed: 1.6ms preprocess, 35.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.8ms\n",
      "\n",
      "0: 384x416 1 matriculas, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 48.1ms\n",
      "\n",
      "0: 384x416 1 matriculas, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.2ms\n",
      "\n",
      "0: 384x416 1 matriculas, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.6ms\n",
      "\n",
      "0: 384x416 (no detections), 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.93\n",
      "Clase --> bus\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.6ms\n",
      "\n",
      "0: 384x416 (no detections), 33.8ms\n",
      "Speed: 1.6ms preprocess, 33.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.92\n",
      "Clase --> bus\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 46.6ms\n",
      "\n",
      "0: 384x416 (no detections), 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.91\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.6ms\n",
      "\n",
      "0: 384x416 (no detections), 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.91\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 46.1ms\n",
      "\n",
      "0: 384x416 1 matriculas, 33.4ms\n",
      "Speed: 1.0ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.3ms\n",
      "\n",
      "0: 384x416 1 matriculas, 33.9ms\n",
      "Speed: 2.0ms preprocess, 33.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.6ms\n",
      "\n",
      "0: 384x416 (no detections), 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.91\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.2ms\n",
      "\n",
      "0: 384x416 1 matriculas, 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.6ms\n",
      "\n",
      "0: 384x416 1 matriculas, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.6ms\n",
      "\n",
      "0: 416x416 2 matriculass, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.0ms\n",
      "\n",
      "0: 416x416 1 matriculas, 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.7ms\n",
      "\n",
      "0: 384x416 1 matriculas, 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.4ms\n",
      "\n",
      "0: 416x416 1 matriculas, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 43.1ms\n",
      "\n",
      "0: 416x416 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.81\n",
      "Clase --> bus\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.6ms\n",
      "\n",
      "0: 384x416 (no detections), 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.77\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.1ms\n",
      "\n",
      "0: 384x416 (no detections), 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.77\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 46.1ms\n",
      "\n",
      "0: 384x416 3 matriculass, 35.4ms\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.6ms\n",
      "\n",
      "0: 416x416 1 matriculas, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.9ms\n",
      "\n",
      "0: 416x416 (no detections), 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.76\n",
      "Clase --> bus\n",
      "Speed: 1.0ms preprocess, 45.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 42.1ms\n",
      "\n",
      "0: 384x416 1 matriculas, 33.7ms\n",
      "Speed: 1.5ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 37.0ms\n",
      "Speed: 0.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 3.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.6ms\n",
      "\n",
      "0: 416x416 (no detections), 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.1ms\n",
      "\n",
      "0: 416x416 1 matriculas, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.7ms\n",
      "\n",
      "0: 416x416 (no detections), 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 40.1ms\n",
      "\n",
      "0: 416x416 (no detections), 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.75\n",
      "Clase --> bus\n",
      "Speed: 1.5ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.1ms\n",
      "\n",
      "0: 416x416 (no detections), 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.1ms\n",
      "\n",
      "0: 416x416 (no detections), 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.8ms\n",
      "\n",
      "0: 416x416 (no detections), 38.2ms\n",
      "Speed: 2.0ms preprocess, 38.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.3ms\n",
      "\n",
      "0: 416x416 (no detections), 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.77\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 50.2ms\n",
      "\n",
      "0: 416x416 (no detections), 41.0ms\n",
      "Speed: 1.2ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.8\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.2ms\n",
      "\n",
      "0: 416x416 (no detections), 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> bus\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 49.2ms\n",
      "\n",
      "0: 416x416 (no detections), 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 47.1ms\n",
      "\n",
      "0: 416x416 2 matriculass, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 45.7ms\n",
      "\n",
      "0: 416x416 4 matriculass, 39.1ms\n",
      "Speed: 1.5ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.9ms\n",
      "\n",
      "0: 416x416 2 matriculass, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 44.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 1 bus, 44.7ms\n",
      "\n",
      "0: 416x416 3 matriculass, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 1 matriculas, 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x320 1 matriculas, 43.6ms\n",
      "Speed: 0.0ms preprocess, 43.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 416x256 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Confianza ---> 0.13\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 3 matriculass, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 1 matriculas, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 1 bus, 44.3ms\n",
      "\n",
      "0: 416x416 2 matriculass, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.37\n",
      "Clase --> car\n",
      "\n",
      "0: 416x320 (no detections), 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.32\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 2 matriculass, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "\n",
      "0: 416x224 (no detections), 41.7ms\n",
      "Speed: 1.0ms preprocess, 41.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 49.2ms\n",
      "\n",
      "0: 416x416 2 matriculass, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.21\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 45.5ms\n",
      "\n",
      "0: 416x384 1 matriculas, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "\n",
      "0: 416x320 (no detections), 31.9ms\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.31\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 (no detections), 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.22\n",
      "Clase --> car\n",
      "\n",
      "0: 416x256 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 1 matriculas, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 1 bus, 48.3ms\n",
      "\n",
      "0: 416x416 4 matriculass, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.45\n",
      "Clase --> car\n",
      "\n",
      "0: 416x352 (no detections), 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.3\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 (no detections), 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> car\n",
      "\n",
      "0: 416x256 (no detections), 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x288 (no detections), 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Confianza ---> 0.13\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 50.6ms\n",
      "\n",
      "0: 416x416 1 matriculas, 42.8ms\n",
      "Speed: 1.1ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.24\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 50.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 cars, 1 bus, 47.6ms\n",
      "\n",
      "0: 416x416 (no detections), 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.53\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.52\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x128 (no detections), 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.41\n",
      "Clase --> car\n",
      "\n",
      "0: 416x224 (no detections), 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.31\n",
      "Clase --> car\n",
      "\n",
      "0: 416x96 (no detections), 27.6ms\n",
      "Speed: 1.0ms preprocess, 27.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 96)\n",
      "Confianza ---> 0.31\n",
      "Clase --> car\n",
      "\n",
      "0: 416x320 (no detections), 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.24\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 47.6ms\n",
      "Speed: 0.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> car\n",
      "\n",
      "0: 416x192 (no detections), 35.2ms\n",
      "Speed: 1.5ms preprocess, 35.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.19\n",
      "Clase --> car\n",
      "\n",
      "0: 416x64 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 64)\n",
      "Confianza ---> 0.17\n",
      "Clase --> car\n",
      "\n",
      "0: 416x320 (no detections), 34.1ms\n",
      "Speed: 0.5ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.11\n",
      "Clase --> car\n",
      "\n",
      "0: 416x256 (no detections), 30.4ms\n",
      "Speed: 1.0ms preprocess, 30.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "\n",
      "0: 416x96 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 96)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.7ms\n",
      "\n",
      "0: 416x96 (no detections), 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 96)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.1ms\n",
      "Speed: 0.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.6ms\n",
      "\n",
      "0: 416x128 1 matriculas, 20.4ms\n",
      "Speed: 1.0ms preprocess, 20.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 35.2ms\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 40.1ms\n",
      "\n",
      "0: 416x128 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 3 matriculass, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "Speed: 2.1ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.6ms\n",
      "\n",
      "0: 416x128 1 matriculas, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 39.4ms\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.25\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 1 matriculas, 37.8ms\n",
      "Speed: 0.0ms preprocess, 37.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 49.7ms\n",
      "\n",
      "0: 416x128 (no detections), 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "Speed: 2.5ms preprocess, 49.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.6ms\n",
      "\n",
      "0: 416x128 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 47.1ms\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 39.1ms\n",
      "Speed: 2.0ms preprocess, 39.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 1 matriculas, 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 43.1ms\n",
      "\n",
      "0: 416x160 (no detections), 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.6ms\n",
      "Speed: 1.2ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.7\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 47.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 38.8ms\n",
      "Speed: 1.0ms preprocess, 38.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 48.2ms\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.6ms\n",
      "Speed: 1.1ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 45.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.6ms\n",
      "Speed: 0.0ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 48.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.3ms\n",
      "Speed: 0.0ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 47.1ms\n",
      "\n",
      "0: 416x192 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 43.4ms\n",
      "Speed: 1.0ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 45.2ms\n",
      "\n",
      "0: 416x224 (no detections), 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 34.9ms\n",
      "Speed: 1.0ms preprocess, 34.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 41.1ms\n",
      "Speed: 1.5ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.24\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.0ms\n",
      "\n",
      "0: 416x224 (no detections), 27.5ms\n",
      "Speed: 1.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 3 matriculass, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.1ms\n",
      "\n",
      "0: 416x224 (no detections), 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 3 matriculass, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.7ms\n",
      "\n",
      "0: 416x224 (no detections), 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.76\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.2ms\n",
      "\n",
      "0: 416x224 (no detections), 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 30.6ms\n",
      "Speed: 1.0ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.77\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.1ms\n",
      "\n",
      "0: 416x224 (no detections), 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 29.6ms\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.1ms\n",
      "\n",
      "0: 416x192 (no detections), 22.2ms\n",
      "Speed: 1.0ms preprocess, 22.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.1ms\n",
      "\n",
      "0: 416x192 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 2 matriculass, 30.1ms\n",
      "Speed: 1.5ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 2 matriculass, 29.2ms\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 39.1ms\n",
      "\n",
      "0: 288x416 1 matriculas, 26.9ms\n",
      "Speed: 1.0ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 41.2ms\n",
      "\n",
      "0: 288x416 3 matriculass, 28.5ms\n",
      "Speed: 0.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 40.6ms\n",
      "\n",
      "0: 288x416 1 matriculas, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.9ms\n",
      "Speed: 1.0ms preprocess, 24.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 30.9ms\n",
      "Speed: 1.0ms preprocess, 30.9ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.77\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 32.1ms\n",
      "Speed: 1.5ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 40.3ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 0.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.75\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 46.1ms\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 0.5ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 32.6ms\n",
      "Speed: 1.1ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.75\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 3 matriculass, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 45.6ms\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> bus\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.6ms\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> bus\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 43.2ms\n",
      "\n",
      "0: 416x192 (no detections), 29.6ms\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 38.6ms\n",
      "Speed: 0.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 45.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 33.0ms\n",
      "Speed: 0.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.75\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 39.6ms\n",
      "Speed: 2.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.2ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 0.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 2 matriculass, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 45.2ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 3 matriculass, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 45.6ms\n",
      "\n",
      "0: 416x160 1 matriculas, 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 34.5ms\n",
      "Speed: 0.0ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.2ms\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 1.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.24\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 31.6ms\n",
      "Speed: 0.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 47.3ms\n",
      "\n",
      "0: 416x192 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 48.4ms\n",
      "Speed: 1.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 47.1ms\n",
      "\n",
      "0: 416x192 (no detections), 24.6ms\n",
      "Speed: 0.0ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 32.6ms\n",
      "Speed: 0.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.1ms\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 3 matriculass, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.3ms\n",
      "\n",
      "0: 416x192 (no detections), 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 29.1ms\n",
      "Speed: 0.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.71\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 2 matriculass, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.0ms\n",
      "\n",
      "0: 416x192 (no detections), 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.7\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.0ms\n",
      "\n",
      "0: 416x192 (no detections), 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.7\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.0ms\n",
      "\n",
      "0: 416x192 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 41.7ms\n",
      "\n",
      "0: 416x192 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 29.6ms\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 41.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 28.1ms\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 2 matriculass, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 39.7ms\n",
      "\n",
      "0: 416x128 (no detections), 29.6ms\n",
      "Speed: 0.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 30.6ms\n",
      "Speed: 1.0ms preprocess, 30.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.25\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 41.1ms\n",
      "\n",
      "0: 416x128 1 matriculas, 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 42.7ms\n",
      "\n",
      "0: 416x416 3 matriculass, 35.1ms\n",
      "Speed: 2.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 40.4ms\n",
      "\n",
      "0: 416x416 2 matriculass, 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 41.4ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 35.5ms\n",
      "Speed: 2.5ms preprocess, 35.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 42.1ms\n",
      "\n",
      "0: 416x416 1 matriculas, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 43.7ms\n",
      "\n",
      "0: 416x416 1 matriculas, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 41.1ms\n",
      "\n",
      "0: 416x416 2 matriculass, 35.6ms\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.7ms\n",
      "Speed: 1.0ms preprocess, 20.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 43.2ms\n",
      "\n",
      "0: 416x416 1 matriculas, 46.2ms\n",
      "Speed: 1.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 43.2ms\n",
      "\n",
      "0: 416x416 1 matriculas, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.1ms\n",
      "Speed: 0.0ms preprocess, 21.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 41.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 42.7ms\n",
      "\n",
      "0: 416x160 (no detections), 21.6ms\n",
      "Speed: 0.0ms preprocess, 21.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 41.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 38.7ms\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.22\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 44.3ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 36.5ms\n",
      "Speed: 1.5ms preprocess, 36.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 42.7ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 35.0ms\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 44.5ms\n",
      "\n",
      "0: 416x416 1 matriculas, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.9ms\n",
      "Speed: 1.0ms preprocess, 24.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 43.1ms\n",
      "\n",
      "0: 416x416 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.76\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x192 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 43.7ms\n",
      "\n",
      "0: 416x192 (no detections), 30.2ms\n",
      "Speed: 0.0ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.22\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 44.1ms\n",
      "\n",
      "0: 416x192 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 50.1ms\n",
      "\n",
      "0: 416x192 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.24\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 41.1ms\n",
      "\n",
      "0: 416x192 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.9ms\n",
      "Speed: 1.0ms preprocess, 34.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 43.1ms\n",
      "\n",
      "0: 416x192 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 40.1ms\n",
      "\n",
      "0: 416x192 (no detections), 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 37.6ms\n",
      "Speed: 0.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 45.1ms\n",
      "\n",
      "0: 416x416 (no detections), 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> bus\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.76\n",
      "Clase --> bus\n",
      "\n",
      "0: 288x416 1 matriculas, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 44.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> bus\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 39.3ms\n",
      "\n",
      "0: 416x160 (no detections), 29.6ms\n",
      "Speed: 0.0ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 34.1ms\n",
      "Speed: 2.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 42.1ms\n",
      "\n",
      "0: 416x416 2 matriculass, 35.9ms\n",
      "Speed: 1.0ms preprocess, 35.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 44.1ms\n",
      "\n",
      "0: 416x416 (no detections), 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 40.7ms\n",
      "\n",
      "0: 416x416 (no detections), 34.0ms\n",
      "Speed: 1.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.71\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x416 (no detections), 30.6ms\n",
      "Speed: 1.0ms preprocess, 30.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 40.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.9ms\n",
      "Speed: 2.0ms preprocess, 34.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> bus\n",
      "\n",
      "0: 384x416 (no detections), 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 3.0ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 40.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 33.8ms\n",
      "Speed: 1.5ms preprocess, 33.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 41.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.8ms\n",
      "Speed: 1.0ms preprocess, 21.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "Speed: 3.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 41.2ms\n",
      "\n",
      "0: 416x160 (no detections), 20.6ms\n",
      "Speed: 0.0ms preprocess, 20.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> bus\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.6ms\n",
      "\n",
      "0: 416x192 (no detections), 23.8ms\n",
      "Speed: 0.0ms preprocess, 23.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "Speed: 2.1ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 31.3ms\n",
      "Speed: 1.0ms preprocess, 31.3ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.3ms\n",
      "Speed: 0.0ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 1 matriculas, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 43.2ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 30.5ms\n",
      "Speed: 0.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 43.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.6ms\n",
      "\n",
      "0: 416x160 (no detections), 20.8ms\n",
      "Speed: 1.0ms preprocess, 20.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 32.5ms\n",
      "Speed: 1.5ms preprocess, 32.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 41.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 32.3ms\n",
      "Speed: 1.0ms preprocess, 32.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.1ms preprocess, 41.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.3ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 30.1ms\n",
      "Speed: 1.5ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 33.1ms\n",
      "Speed: 1.1ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 51.1ms\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 34.6ms\n",
      "Speed: 0.0ms preprocess, 34.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 41.7ms\n",
      "\n",
      "0: 416x192 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 41.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 39.7ms\n",
      "\n",
      "0: 416x192 (no detections), 22.3ms\n",
      "Speed: 1.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 31.3ms\n",
      "Speed: 1.0ms preprocess, 31.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 41.2ms\n",
      "\n",
      "0: 416x192 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 1 matriculas, 30.1ms\n",
      "Speed: 1.4ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 44.6ms\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 35.1ms\n",
      "Speed: 0.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 40.1ms\n",
      "\n",
      "0: 416x192 (no detections), 22.1ms\n",
      "Speed: 1.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.1ms\n",
      "Speed: 2.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.2ms\n",
      "\n",
      "0: 416x192 (no detections), 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.7ms\n",
      "\n",
      "0: 416x192 (no detections), 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.7ms\n",
      "\n",
      "0: 416x160 (no detections), 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 47.2ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7 cars, 1 bus, 43.2ms\n",
      "\n",
      "0: 416x416 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 33.6ms\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.59\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 47.1ms\n",
      "Speed: 0.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.52\n",
      "Clase --> bus\n",
      "\n",
      "0: 288x416 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.48\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 32.6ms\n",
      "Speed: 2.1ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.35\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 22.1ms\n",
      "Speed: 0.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 33.1ms\n",
      "Speed: 1.5ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.24\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 1 matriculas, 32.2ms\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 49.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.5ms preprocess, 49.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.7ms\n",
      "\n",
      "0: 416x160 (no detections), 26.6ms\n",
      "Speed: 0.0ms preprocess, 26.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 48.2ms\n",
      "\n",
      "0: 416x160 (no detections), 27.3ms\n",
      "Speed: 0.0ms preprocess, 27.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.6ms\n",
      "\n",
      "0: 384x416 (no detections), 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 21.7ms\n",
      "Speed: 1.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 35.1ms\n",
      "Speed: 0.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 35.6ms\n",
      "Speed: 0.0ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.9ms\n",
      "\n",
      "0: 416x416 (no detections), 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.5ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.1ms\n",
      "\n",
      "0: 416x416 (no detections), 34.6ms\n",
      "Speed: 0.0ms preprocess, 34.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 41.0ms\n",
      "\n",
      "0: 416x160 (no detections), 30.6ms\n",
      "Speed: 0.0ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.2ms\n",
      "Speed: 1.0ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.8ms\n",
      "Speed: 1.0ms preprocess, 34.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.0ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.2ms\n",
      "\n",
      "0: 416x384 (no detections), 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 21.7ms\n",
      "Speed: 0.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 43.1ms\n",
      "\n",
      "0: 416x384 (no detections), 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 1.6ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 34.8ms\n",
      "Speed: 1.0ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 47.3ms\n",
      "\n",
      "0: 416x384 (no detections), 33.6ms\n",
      "Speed: 0.5ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 47.6ms\n",
      "\n",
      "0: 416x384 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x192 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 44.3ms\n",
      "\n",
      "0: 416x192 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 38.8ms\n",
      "Speed: 1.0ms preprocess, 38.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 47.6ms\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.1ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 47.2ms\n",
      "\n",
      "0: 416x192 (no detections), 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 47.8ms\n",
      "\n",
      "0: 416x160 (no detections), 24.9ms\n",
      "Speed: 1.0ms preprocess, 24.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 37.1ms\n",
      "Speed: 0.5ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.2ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 41.6ms\n",
      "\n",
      "0: 416x192 (no detections), 24.3ms\n",
      "Speed: 1.0ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 40.2ms\n",
      "\n",
      "0: 416x160 (no detections), 22.3ms\n",
      "Speed: 1.0ms preprocess, 22.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 29.7ms\n",
      "Speed: 1.0ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 1 matriculas, 30.5ms\n",
      "Speed: 0.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.1ms\n",
      "\n",
      "0: 416x160 (no detections), 26.6ms\n",
      "Speed: 0.0ms preprocess, 26.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.4ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 cars, 1 bus, 44.6ms\n",
      "\n",
      "0: 416x416 (no detections), 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 29.6ms\n",
      "Speed: 0.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.56\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 30.5ms\n",
      "Speed: 0.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 30.9ms\n",
      "Speed: 1.0ms preprocess, 30.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 31.8ms\n",
      "Speed: 1.0ms preprocess, 31.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.25\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 1 matriculas, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 416x352 2 matriculass, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 28.2ms\n",
      "Speed: 1.0ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.3ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.5ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "\n",
      "0: 416x192 (no detections), 25.5ms\n",
      "Speed: 0.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.6ms\n",
      "\n",
      "0: 416x192 (no detections), 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 28.3ms\n",
      "Speed: 1.0ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.6ms\n",
      "Speed: 1.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 28.7ms\n",
      "Speed: 1.0ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 43.4ms\n",
      "\n",
      "0: 416x160 (no detections), 22.3ms\n",
      "Speed: 1.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.5ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 40.3ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 27.2ms\n",
      "Speed: 1.0ms preprocess, 27.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "Speed: 3.0ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 40.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 28.1ms\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 1 matriculas, 28.4ms\n",
      "Speed: 0.0ms preprocess, 28.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 44.3ms\n",
      "\n",
      "0: 416x160 (no detections), 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 30.3ms\n",
      "Speed: 1.0ms preprocess, 30.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 28.0ms\n",
      "Speed: 0.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 28.2ms\n",
      "Speed: 1.0ms preprocess, 28.2ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 46.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.7\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 43.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.8ms\n",
      "Speed: 1.0ms preprocess, 22.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 30.4ms\n",
      "Speed: 1.0ms preprocess, 30.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 29.5ms\n",
      "Speed: 0.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 43.9ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.9ms\n",
      "Speed: 0.0ms preprocess, 31.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 29.6ms\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 33.5ms\n",
      "Speed: 0.0ms preprocess, 33.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 45.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 44.6ms\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.25\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 38.7ms\n",
      "Speed: 0.0ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.21\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 44.0ms\n",
      "\n",
      "0: 416x192 (no detections), 27.5ms\n",
      "Speed: 1.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 35.1ms\n",
      "Speed: 0.0ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.21\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 46.3ms\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 44.6ms\n",
      "\n",
      "0: 416x192 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 46.1ms\n",
      "\n",
      "0: 416x192 (no detections), 27.5ms\n",
      "Speed: 0.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 41.6ms\n",
      "Speed: 0.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 34.9ms\n",
      "Speed: 0.0ms preprocess, 34.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 42.4ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.21\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 48.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 36.5ms\n",
      "Speed: 0.0ms preprocess, 36.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 50.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.7\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.3ms\n",
      "Speed: 1.0ms preprocess, 24.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.71\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 44.6ms\n",
      "\n",
      "0: 320x416 (no detections), 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 45.0ms\n",
      "\n",
      "0: 320x416 (no detections), 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 37.3ms\n",
      "Speed: 0.0ms preprocess, 37.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 43.1ms\n",
      "\n",
      "0: 320x416 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 43.1ms\n",
      "\n",
      "0: 320x416 (no detections), 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 41.1ms\n",
      "Speed: 0.0ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 47.8ms\n",
      "\n",
      "0: 320x416 (no detections), 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 45.6ms\n",
      "\n",
      "0: 320x416 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 38.1ms\n",
      "Speed: 1.5ms preprocess, 38.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 44.2ms\n",
      "\n",
      "0: 320x416 1 matriculas, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 31.9ms\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 46.1ms\n",
      "\n",
      "0: 320x416 2 matriculass, 30.9ms\n",
      "Speed: 1.0ms preprocess, 30.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 (no detections), 32.6ms\n",
      "Speed: 0.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 47.1ms\n",
      "\n",
      "0: 320x416 1 matriculas, 32.5ms\n",
      "Speed: 0.0ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 38.1ms\n",
      "Speed: 0.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 52.9ms\n",
      "\n",
      "0: 320x416 (no detections), 31.6ms\n",
      "Speed: 0.0ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "Speed: 3.5ms preprocess, 52.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 42.0ms\n",
      "\n",
      "0: 320x416 (no detections), 32.4ms\n",
      "Speed: 0.0ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.59\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.57\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 33.5ms\n",
      "Speed: 0.0ms preprocess, 33.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.56\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.53\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.37\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 1 matriculas, 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 2 matriculass, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 0.5ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 40.1ms\n",
      "Speed: 0.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 36.1ms\n",
      "Speed: 1.5ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.9ms\n",
      "Speed: 0.0ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 45.1ms\n",
      "\n",
      "0: 320x416 (no detections), 30.2ms\n",
      "Speed: 1.0ms preprocess, 30.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 35.5ms\n",
      "Speed: 0.0ms preprocess, 35.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.57\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.55\n",
      "Clase --> car\n",
      "\n",
      "0: 256x416 (no detections), 28.7ms\n",
      "Speed: 1.0ms preprocess, 28.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.54\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.53\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.36\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.29\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.24\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 1 matriculas, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 46.6ms\n",
      "\n",
      "0: 416x416 (no detections), 37.6ms\n",
      "Speed: 1.5ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.57\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 (no detections), 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.56\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 32.1ms\n",
      "Speed: 0.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.54\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.37\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.29\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 1 matriculas, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.22\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.25\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 40.7ms\n",
      "Speed: 0.0ms preprocess, 40.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.14\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 43.6ms\n",
      "\n",
      "0: 416x416 (no detections), 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.59\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 (no detections), 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 32.5ms\n",
      "Speed: 0.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.57\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.53\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.0ms\n",
      "Speed: 1.0ms preprocess, 34.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.38\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.31\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.27\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 1 matriculas, 35.3ms\n",
      "Speed: 0.0ms preprocess, 35.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> car\n",
      "\n",
      "0: 256x416 (no detections), 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 45.6ms\n",
      "\n",
      "0: 416x416 (no detections), 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.59\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.59\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 32.5ms\n",
      "Speed: 0.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.57\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.54\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 32.2ms\n",
      "Speed: 0.0ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.39\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.32\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 1 matriculas, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.25\n",
      "Clase --> car\n",
      "\n",
      "0: 416x128 (no detections), 23.6ms\n",
      "Speed: 0.5ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11 cars, 44.1ms\n",
      "\n",
      "0: 416x416 (no detections), 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 (no detections), 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.59\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.58\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 34.1ms\n",
      "Speed: 2.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.54\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.4\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 1 matriculas, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 2 matriculass, 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 2 matriculass, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.24\n",
      "Clase --> person\n",
      "\n",
      "0: 416x224 (no detections), 39.9ms\n",
      "Speed: 0.0ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> car\n",
      "\n",
      "0: 256x416 (no detections), 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> car\n",
      "Speed: 2.5ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 42.6ms\n",
      "\n",
      "0: 416x416 (no detections), 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.59\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.56\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 32.5ms\n",
      "Speed: 1.5ms preprocess, 32.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.55\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.1ms\n",
      "Speed: 0.5ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.4\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 1 matriculas, 35.3ms\n",
      "Speed: 1.5ms preprocess, 35.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "\n",
      "0: 416x96 (no detections), 26.5ms\n",
      "Speed: 1.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 96)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.25\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 35.9ms\n",
      "Speed: 1.0ms preprocess, 35.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.13\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 62.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.7ms\n",
      "\n",
      "0: 416x128 (no detections), 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "\n",
      "0: 416x128 (no detections), 21.6ms\n",
      "Speed: 1.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "\n",
      "0: 416x192 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.8ms\n",
      "\n",
      "0: 416x128 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.6ms\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.5ms\n",
      "\n",
      "0: 416x96 (no detections), 19.0ms\n",
      "Speed: 0.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 96)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 27.1ms\n",
      "Speed: 0.0ms preprocess, 27.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.4ms\n",
      "\n",
      "0: 416x96 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 96)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.7ms\n",
      "\n",
      "0: 416x128 (no detections), 19.9ms\n",
      "Speed: 1.0ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 19.6ms\n",
      "Speed: 1.0ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.0ms\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 0.5ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 0.0ms preprocess, 22.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.8ms\n",
      "\n",
      "0: 416x128 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.6ms\n",
      "\n",
      "0: 416x128 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.5ms\n",
      "Speed: 0.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.1ms\n",
      "Speed: 0.0ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 47.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.9ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.7ms\n",
      "Speed: 0.0ms preprocess, 24.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.8ms\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 31.4ms\n",
      "Speed: 1.0ms preprocess, 31.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 47.1ms\n",
      "\n",
      "0: 416x192 (no detections), 24.2ms\n",
      "Speed: 1.0ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.9ms\n",
      "Speed: 1.0ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.6ms\n",
      "\n",
      "0: 416x192 (no detections), 24.6ms\n",
      "Speed: 0.0ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 32.6ms\n",
      "Speed: 0.0ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.6ms\n",
      "\n",
      "0: 416x192 (no detections), 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 26.0ms\n",
      "Speed: 1.1ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 0.5ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 46.7ms\n",
      "\n",
      "0: 416x192 (no detections), 26.6ms\n",
      "Speed: 1.0ms preprocess, 26.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 23.0ms\n",
      "Speed: 0.7ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 31.6ms\n",
      "Speed: 0.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.1ms\n",
      "\n",
      "0: 416x224 (no detections), 30.5ms\n",
      "Speed: 1.1ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 36.0ms\n",
      "Speed: 0.0ms preprocess, 36.0ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 46.7ms\n",
      "\n",
      "0: 416x224 (no detections), 29.5ms\n",
      "Speed: 0.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 1 matriculas, 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.6ms\n",
      "\n",
      "0: 416x224 (no detections), 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.6ms\n",
      "Speed: 0.0ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.1ms\n",
      "\n",
      "0: 416x192 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.4ms\n",
      "\n",
      "0: 416x192 (no detections), 23.8ms\n",
      "Speed: 1.0ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.4ms\n",
      "\n",
      "0: 416x192 (no detections), 22.9ms\n",
      "Speed: 1.0ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.6ms\n",
      "\n",
      "0: 416x224 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "\n",
      "0: 416x256 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.4ms\n",
      "\n",
      "0: 416x224 (no detections), 27.7ms\n",
      "Speed: 0.0ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 49.7ms\n",
      "\n",
      "0: 416x224 (no detections), 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 49.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.9ms\n",
      "\n",
      "0: 416x224 (no detections), 27.2ms\n",
      "Speed: 1.0ms preprocess, 27.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.6ms\n",
      "\n",
      "0: 416x128 (no detections), 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.2ms\n",
      "Speed: 1.0ms preprocess, 22.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 45.6ms\n",
      "\n",
      "0: 416x128 1 matriculas, 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.9ms\n",
      "Speed: 1.0ms preprocess, 21.9ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 47.3ms\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 42.3ms\n",
      "\n",
      "0: 416x128 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 39.1ms\n",
      "Speed: 0.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 47.9ms\n",
      "\n",
      "0: 416x128 1 matriculas, 19.9ms\n",
      "Speed: 1.0ms preprocess, 19.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 44.8ms\n",
      "\n",
      "0: 416x128 (no detections), 25.1ms\n",
      "Speed: 1.0ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.8ms\n",
      "Speed: 0.0ms preprocess, 21.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 32.3ms\n",
      "Speed: 1.0ms preprocess, 32.3ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 57.1ms\n",
      "\n",
      "0: 416x128 (no detections), 22.1ms\n",
      "Speed: 1.0ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 0.0ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 57.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.6ms\n",
      "\n",
      "0: 416x128 (no detections), 22.6ms\n",
      "Speed: 0.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 32.1ms\n",
      "Speed: 0.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 45.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.6ms\n",
      "Speed: 0.0ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 33.6ms\n",
      "Speed: 0.5ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 45.7ms\n",
      "\n",
      "0: 416x192 (no detections), 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 47.1ms\n",
      "Speed: 0.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 45.1ms\n",
      "\n",
      "0: 416x192 (no detections), 26.0ms\n",
      "Speed: 0.5ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 29.9ms\n",
      "Speed: 1.0ms preprocess, 29.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 26.1ms\n",
      "Speed: 0.0ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 46.1ms\n",
      "\n",
      "0: 416x192 (no detections), 27.6ms\n",
      "Speed: 1.0ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.3ms\n",
      "Speed: 0.0ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 31.8ms\n",
      "Speed: 1.0ms preprocess, 31.8ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 0.5ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.9ms\n",
      "Speed: 0.0ms preprocess, 24.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 47.1ms\n",
      "\n",
      "0: 416x160 (no detections), 41.6ms\n",
      "Speed: 0.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 33.0ms\n",
      "Speed: 0.0ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.1ms\n",
      "Speed: 0.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 33.5ms\n",
      "Speed: 0.0ms preprocess, 33.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 3 matriculass, 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 41.0ms\n",
      "\n",
      "0: 416x128 (no detections), 18.6ms\n",
      "Speed: 0.0ms preprocess, 18.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 26.5ms\n",
      "Speed: 0.0ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 1 matriculas, 30.2ms\n",
      "Speed: 1.0ms preprocess, 30.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 56.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 0.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 28.1ms\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 4 matriculass, 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 56.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.2ms\n",
      "Speed: 1.0ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 18.6ms\n",
      "Speed: 1.0ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 30.2ms\n",
      "Speed: 0.0ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 53.7ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 2 matriculass, 30.3ms\n",
      "Speed: 1.0ms preprocess, 30.3ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.8ms\n",
      "Speed: 1.0ms preprocess, 20.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.5ms preprocess, 53.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 42.2ms\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 28.6ms\n",
      "Speed: 1.0ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 29.6ms\n",
      "Speed: 0.0ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x192 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 44.7ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 30.4ms\n",
      "Speed: 1.0ms preprocess, 30.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 28.5ms\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 51.7ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 51.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 1 matriculas, 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 40.2ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.5ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 30.5ms\n",
      "Speed: 0.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> car\n",
      "\n",
      "0: 256x416 1 matriculas, 28.5ms\n",
      "Speed: 0.0ms preprocess, 28.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 42.1ms\n",
      "\n",
      "0: 416x192 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 29.5ms\n",
      "Speed: 1.1ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 27.4ms\n",
      "Speed: 1.0ms preprocess, 27.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 42.1ms\n",
      "\n",
      "0: 416x224 (no detections), 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 28.2ms\n",
      "Speed: 0.0ms preprocess, 28.2ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 39.8ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 30.7ms\n",
      "Speed: 1.0ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 57.1ms\n",
      "Speed: 1.1ms preprocess, 57.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 40.1ms\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.2ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 26.5ms\n",
      "Speed: 1.0ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 3 matriculass, 37.1ms\n",
      "Speed: 0.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 28.6ms\n",
      "Speed: 1.1ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 3 matriculass, 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 41.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.6ms\n",
      "Speed: 1.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 29.4ms\n",
      "Speed: 0.0ms preprocess, 29.4ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 36.4ms\n",
      "Speed: 0.0ms preprocess, 36.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 42.2ms\n",
      "\n",
      "0: 416x160 (no detections), 20.7ms\n",
      "Speed: 0.0ms preprocess, 20.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 29.9ms\n",
      "Speed: 1.0ms preprocess, 29.9ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 35.6ms\n",
      "Speed: 2.0ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.1ms\n",
      "Speed: 0.0ms preprocess, 21.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 40.0ms\n",
      "\n",
      "0: 416x160 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 28.5ms\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 43.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 29.1ms\n",
      "Speed: 0.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 27.5ms\n",
      "Speed: 0.0ms preprocess, 27.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 3.0ms preprocess, 43.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 43.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 23.9ms\n",
      "Speed: 1.0ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 29.8ms\n",
      "Speed: 1.0ms preprocess, 29.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 3.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x224 (no detections), 28.4ms\n",
      "Speed: 0.0ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 0.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 29.0ms\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 3.5ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.6ms\n",
      "Speed: 0.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 26.6ms\n",
      "Speed: 1.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 (no detections), 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.8ms\n",
      "Speed: 1.0ms preprocess, 22.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 21.8ms\n",
      "Speed: 1.0ms preprocess, 21.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.3ms\n",
      "Speed: 1.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 20.5ms\n",
      "Speed: 0.0ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 54.6ms\n",
      "\n",
      "0: 416x192 (no detections), 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.4ms\n",
      "Speed: 0.0ms preprocess, 22.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.6ms\n",
      "Speed: 0.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 54.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.1ms\n",
      "Speed: 0.0ms preprocess, 21.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 2 matriculass, 27.7ms\n",
      "Speed: 1.0ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 2 matriculass, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 40.1ms\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 19.0ms\n",
      "Speed: 0.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 29.5ms\n",
      "Speed: 0.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 18.7ms\n",
      "Speed: 1.0ms preprocess, 18.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.7ms\n",
      "Speed: 1.0ms preprocess, 21.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 29.5ms\n",
      "Speed: 0.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 39.7ms\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 1 matriculas, 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 42.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.7ms\n",
      "Speed: 0.0ms preprocess, 24.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 33.6ms\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 46.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.2ms\n",
      "Speed: 1.0ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.2ms\n",
      "Speed: 0.0ms preprocess, 32.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 44.5ms\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 1.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 2.5ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.7ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 0.9ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.8ms\n",
      "\n",
      "0: 416x160 (no detections), 24.4ms\n",
      "Speed: 1.0ms preprocess, 24.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.3ms\n",
      "Speed: 1.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 45.5ms\n",
      "\n",
      "0: 416x192 1 matriculas, 25.4ms\n",
      "Speed: 0.0ms preprocess, 25.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.22\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.2ms\n",
      "Speed: 0.0ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 44.3ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.3ms\n",
      "Speed: 1.0ms preprocess, 25.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.7ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.2ms\n",
      "\n",
      "0: 416x160 (no detections), 20.6ms\n",
      "Speed: 1.0ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.6ms\n",
      "\n",
      "0: 416x160 (no detections), 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.2ms\n",
      "\n",
      "0: 416x160 (no detections), 22.9ms\n",
      "Speed: 1.0ms preprocess, 22.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.4ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.4ms\n",
      "Speed: 0.0ms preprocess, 21.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 27.9ms\n",
      "Speed: 0.0ms preprocess, 27.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.0ms\n",
      "\n",
      "0: 416x160 (no detections), 23.3ms\n",
      "Speed: 0.0ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 52.6ms\n",
      "\n",
      "0: 416x160 1 matriculas, 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 46.2ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.5ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 46.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 43.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.6ms\n",
      "Speed: 1.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.2ms\n",
      "Speed: 1.0ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 44.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.8ms\n",
      "\n",
      "0: 416x160 (no detections), 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.9ms\n",
      "Speed: 1.0ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 43.6ms\n",
      "\n",
      "0: 416x160 (no detections), 20.7ms\n",
      "Speed: 1.0ms preprocess, 20.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.8ms\n",
      "\n",
      "0: 416x192 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.6ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.7ms\n",
      "Speed: 1.0ms preprocess, 24.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 48.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 0.0ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 19.6ms\n",
      "Speed: 1.0ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.1ms\n",
      "Speed: 0.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 63.2ms\n",
      "\n",
      "0: 416x160 (no detections), 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 26.0ms\n",
      "Speed: 0.5ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.2ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 26.1ms\n",
      "Speed: 0.0ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 48.6ms\n",
      "\n",
      "0: 416x160 (no detections), 25.7ms\n",
      "Speed: 0.0ms preprocess, 25.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 27.7ms\n",
      "Speed: 1.0ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 48.6ms\n",
      "\n",
      "0: 416x160 (no detections), 28.6ms\n",
      "Speed: 1.0ms preprocess, 28.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 26.8ms\n",
      "Speed: 0.0ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 58.1ms\n",
      "Speed: 1.5ms preprocess, 58.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 53.1ms\n",
      "\n",
      "0: 416x160 (no detections), 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x224 (no detections), 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Confianza ---> 0.78\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 53.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 57.9ms\n",
      "\n",
      "0: 416x288 (no detections), 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Confianza ---> 0.79\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.7ms\n",
      "Speed: 1.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 57.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x288 (no detections), 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Confianza ---> 0.8\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 44.4ms\n",
      "\n",
      "0: 416x288 (no detections), 52.1ms\n",
      "Speed: 2.1ms preprocess, 52.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Confianza ---> 0.84\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 48.6ms\n",
      "\n",
      "0: 416x320 (no detections), 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.87\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 46.7ms\n",
      "\n",
      "0: 416x320 1 matriculas, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.9ms\n",
      "Speed: 0.0ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 44.2ms\n",
      "\n",
      "0: 416x320 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.92\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 43.6ms\n",
      "\n",
      "0: 416x352 1 matriculas, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.8ms\n",
      "\n",
      "0: 416x384 (no detections), 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.91\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 44.5ms\n",
      "\n",
      "0: 416x416 (no detections), 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.89\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 22.3ms\n",
      "Speed: 0.0ms preprocess, 22.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 43.1ms\n",
      "\n",
      "0: 416x416 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.91\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 1.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.5ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 40.1ms\n",
      "\n",
      "0: 384x416 1 matriculas, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 0.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 28.3ms\n",
      "Speed: 0.0ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.2ms\n",
      "\n",
      "0: 384x416 1 matriculas, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 40.6ms\n",
      "\n",
      "0: 352x416 2 matriculass, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 25.1ms\n",
      "Speed: 1.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 26.5ms\n",
      "Speed: 0.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 42.1ms\n",
      "\n",
      "0: 352x416 1 matriculas, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.7ms\n",
      "Speed: 1.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 46.8ms\n",
      "\n",
      "0: 320x416 1 matriculas, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.9ms\n",
      "Speed: 1.0ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 41.3ms\n",
      "\n",
      "0: 320x416 1 matriculas, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 20.6ms\n",
      "Speed: 0.0ms preprocess, 20.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 40.1ms\n",
      "\n",
      "0: 320x416 2 matriculass, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 43.6ms\n",
      "\n",
      "0: 320x416 2 matriculass, 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x192 (no detections), 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.7ms\n",
      "Speed: 1.0ms preprocess, 20.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 (no detections), 35.0ms\n",
      "Speed: 0.0ms preprocess, 35.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 44.1ms\n",
      "\n",
      "0: 320x416 2 matriculass, 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.5ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 28.6ms\n",
      "Speed: 1.0ms preprocess, 28.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 43.4ms\n",
      "\n",
      "0: 320x416 1 matriculas, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 0.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 43.1ms\n",
      "\n",
      "0: 288x416 1 matriculas, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 19.7ms\n",
      "Speed: 1.0ms preprocess, 19.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 1 matriculas, 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 44.6ms\n",
      "\n",
      "0: 288x416 1 matriculas, 29.5ms\n",
      "Speed: 1.5ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.6ms\n",
      "Speed: 1.0ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 44.0ms\n",
      "\n",
      "0: 288x416 2 matriculass, 27.5ms\n",
      "Speed: 1.0ms preprocess, 27.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 40.6ms\n",
      "\n",
      "0: 288x416 1 matriculas, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.1ms\n",
      "\n",
      "0: 288x416 1 matriculas, 29.8ms\n",
      "Speed: 1.0ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 43.5ms\n",
      "\n",
      "0: 288x416 2 matriculass, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x352 1 matriculas, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.8ms\n",
      "\n",
      "0: 288x416 1 matriculas, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 motorcycle, 40.0ms\n",
      "\n",
      "0: 288x416 1 matriculas, 28.1ms\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 1 matriculas, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 45.1ms\n",
      "\n",
      "0: 256x416 1 matriculas, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 40.4ms\n",
      "\n",
      "0: 256x416 1 matriculas, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 42.2ms\n",
      "\n",
      "0: 256x416 1 matriculas, 28.0ms\n",
      "Speed: 0.5ms preprocess, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 40.0ms\n",
      "\n",
      "0: 256x416 1 matriculas, 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.1ms\n",
      "Speed: 0.0ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 48.6ms\n",
      "\n",
      "0: 256x416 2 matriculass, 26.6ms\n",
      "Speed: 0.0ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.4ms\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 motorcycle, 43.6ms\n",
      "\n",
      "0: 256x416 2 matriculass, 27.1ms\n",
      "Speed: 1.0ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 43.1ms\n",
      "\n",
      "0: 256x416 3 matriculass, 28.2ms\n",
      "Speed: 1.0ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.2ms\n",
      "\n",
      "0: 256x416 2 matriculass, 27.5ms\n",
      "Speed: 0.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 42.6ms\n",
      "\n",
      "0: 224x416 2 matriculass, 41.1ms\n",
      "Speed: 0.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Confianza ---> 0.22\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 42.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.1ms\n",
      "\n",
      "0: 256x416 2 matriculass, 28.8ms\n",
      "Speed: 1.0ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.2ms\n",
      "\n",
      "0: 256x416 1 matriculas, 29.5ms\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 46.1ms\n",
      "\n",
      "0: 288x416 2 matriculass, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.1ms\n",
      "\n",
      "0: 288x416 2 matriculass, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.3ms\n",
      "Speed: 1.0ms preprocess, 25.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.9ms\n",
      "\n",
      "0: 288x416 2 matriculass, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 47.6ms\n",
      "\n",
      "0: 288x416 1 matriculas, 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.6ms\n",
      "Speed: 1.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.1ms\n",
      "\n",
      "0: 288x416 2 matriculass, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.5ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 46.1ms\n",
      "\n",
      "0: 320x416 2 matriculass, 31.2ms\n",
      "Speed: 1.0ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.1ms\n",
      "\n",
      "0: 320x416 2 matriculass, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 49.2ms\n",
      "\n",
      "0: 320x416 2 matriculass, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 1.0ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 47.1ms\n",
      "\n",
      "0: 320x416 2 matriculass, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 40.1ms\n",
      "Speed: 0.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.7ms\n",
      "Speed: 1.0ms preprocess, 24.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.2ms\n",
      "\n",
      "0: 320x416 2 matriculass, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 22.6ms\n",
      "Speed: 0.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.1ms\n",
      "\n",
      "0: 416x128 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "\n",
      "0: 416x128 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.6ms\n",
      "\n",
      "0: 416x128 (no detections), 24.4ms\n",
      "Speed: 1.0ms preprocess, 24.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 1.4ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.7ms\n",
      "Speed: 1.0ms preprocess, 25.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.5ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "\n",
      "0: 416x128 (no detections), 22.6ms\n",
      "Speed: 0.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 0.5ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 21.5ms\n",
      "Speed: 0.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 45.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 (no detections), 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.2ms\n",
      "Speed: 1.0ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.6ms\n",
      "Speed: 0.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 52.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 52.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11 cars, 44.1ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 1 matriculas, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.54\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 1 matriculas, 30.5ms\n",
      "Speed: 0.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.21\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.46\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 2 matriculass, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "\n",
      "0: 256x416 (no detections), 25.4ms\n",
      "Speed: 1.0ms preprocess, 25.4ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.3\n",
      "Clase --> car\n",
      "\n",
      "0: 416x288 (no detections), 52.6ms\n",
      "Speed: 1.5ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Confianza ---> 0.27\n",
      "Clase --> car\n",
      "\n",
      "0: 416x352 (no detections), 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.23\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 32.0ms\n",
      "Speed: 0.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.17\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 1 matriculas, 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 (no detections), 34.3ms\n",
      "Speed: 0.0ms preprocess, 34.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.11\n",
      "Clase --> car\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.6ms\n",
      "\n",
      "0: 416x160 (no detections), 20.9ms\n",
      "Speed: 1.0ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.2ms\n",
      "\n",
      "0: 416x160 (no detections), 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.4ms\n",
      "\n",
      "0: 416x160 (no detections), 22.8ms\n",
      "Speed: 0.0ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 41.6ms\n",
      "\n",
      "0: 416x192 (no detections), 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.5\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 29.6ms\n",
      "Speed: 0.0ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.48\n",
      "Clase --> car\n",
      "\n",
      "0: 192x416 (no detections), 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "Confianza ---> 0.4\n",
      "Clase --> car\n",
      "\n",
      "0: 416x192 (no detections), 26.0ms\n",
      "Speed: 0.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "\n",
      "0: 416x320 (no detections), 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.37\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 1 matriculas, 36.6ms\n",
      "Speed: 2.0ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 45.6ms\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.37\n",
      "Clase --> car\n",
      "\n",
      "0: 256x416 (no detections), 27.1ms\n",
      "Speed: 1.0ms preprocess, 27.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Confianza ---> 0.34\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 29.6ms\n",
      "Speed: 0.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.32\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 2 matriculass, 34.1ms\n",
      "Speed: 0.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "\n",
      "0: 416x352 1 matriculas, 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 2 matriculass, 34.9ms\n",
      "Speed: 1.0ms preprocess, 34.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 1 matriculas, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "\n",
      "0: 416x352 2 matriculass, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "\n",
      "0: 416x384 1 matriculas, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.4ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.5ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 42.6ms\n",
      "\n",
      "0: 416x160 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 45.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 1 matriculas, 50.1ms\n",
      "Speed: 1.0ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 21.6ms\n",
      "Speed: 1.0ms preprocess, 21.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 55.2ms\n",
      "\n",
      "0: 416x160 (no detections), 24.3ms\n",
      "Speed: 0.0ms preprocess, 24.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 1.3ms preprocess, 55.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.3ms\n",
      "\n",
      "0: 320x416 1 matriculas, 34.2ms\n",
      "Speed: 0.0ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.4ms\n",
      "Speed: 1.0ms preprocess, 25.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 45.3ms\n",
      "\n",
      "0: 320x416 1 matriculas, 32.5ms\n",
      "Speed: 0.0ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.6ms\n",
      "\n",
      "0: 320x416 3 matriculass, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.16\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.6ms\n",
      "Speed: 0.0ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.5ms\n",
      "\n",
      "0: 416x416 2 matriculass, 46.9ms\n",
      "Speed: 1.0ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.25\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 46.6ms\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 384x416 1 matriculas, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 43.6ms\n",
      "\n",
      "0: 320x416 2 matriculass, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 48.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.8ms\n",
      "Speed: 1.3ms preprocess, 25.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 33.5ms\n",
      "Speed: 0.0ms preprocess, 33.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 47.1ms\n",
      "\n",
      "0: 416x128 (no detections), 26.1ms\n",
      "Speed: 0.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "\n",
      "0: 192x416 (no detections), 36.2ms\n",
      "Speed: 0.0ms preprocess, 36.2ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 1 matriculas, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 3 matriculass, 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 45.1ms\n",
      "\n",
      "0: 416x128 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 160x416 (no detections), 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 1 matriculas, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 28.4ms\n",
      "Speed: 0.0ms preprocess, 28.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 47.6ms\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 32.1ms\n",
      "Speed: 0.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.1ms\n",
      "\n",
      "0: 320x416 1 matriculas, 32.4ms\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 47.6ms\n",
      "\n",
      "0: 320x416 1 matriculas, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 26.0ms\n",
      "Speed: 0.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 44.3ms\n",
      "\n",
      "0: 416x160 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.2ms\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.7ms\n",
      "\n",
      "0: 416x160 (no detections), 26.2ms\n",
      "Speed: 1.0ms preprocess, 26.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 46.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 47.1ms\n",
      "\n",
      "0: 416x416 2 matriculass, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 2 matriculass, 34.6ms\n",
      "Speed: 0.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 22.9ms\n",
      "Speed: 0.5ms preprocess, 22.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 26.5ms\n",
      "Speed: 0.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 2 matriculass, 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 1 matriculas, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 224x416 (no detections), 40.0ms\n",
      "Speed: 0.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Confianza ---> 0.38\n",
      "Clase --> car\n",
      "\n",
      "0: 192x416 (no detections), 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "Confianza ---> 0.37\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 1 matriculas, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.19\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 39.6ms\n",
      "Speed: 0.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.25\n",
      "Clase --> car\n",
      "\n",
      "0: 416x320 (no detections), 44.9ms\n",
      "Speed: 1.0ms preprocess, 44.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.24\n",
      "Clase --> car\n",
      "\n",
      "0: 416x320 1 matriculas, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 416x352 1 matriculas, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.14\n",
      "Clase --> person\n",
      "\n",
      "0: 416x288 (no detections), 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Confianza ---> 0.13\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.12\n",
      "Clase --> car\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "\n",
      "0: 416x192 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.2ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "\n",
      "0: 416x192 (no detections), 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 26.5ms\n",
      "Speed: 1.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 56.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.2ms\n",
      "Speed: 1.0ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "\n",
      "0: 352x416 1 matriculas, 35.6ms\n",
      "Speed: 1.1ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 2 matriculass, 42.9ms\n",
      "Speed: 1.0ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 30.7ms\n",
      "Speed: 1.0ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.11\n",
      "Clase --> person\n",
      "\n",
      "0: 416x416 (no detections), 41.7ms\n",
      "Speed: 1.5ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.41\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.41\n",
      "Clase --> car\n",
      "\n",
      "0: 192x416 (no detections), 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "Confianza ---> 0.39\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 39.8ms\n",
      "Speed: 0.0ms preprocess, 39.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Confianza ---> 0.38\n",
      "Clase --> car\n",
      "\n",
      "0: 416x384 (no detections), 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Confianza ---> 0.34\n",
      "Clase --> car\n",
      "\n",
      "0: 416x352 1 matriculas, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 (no detections), 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.22\n",
      "Clase --> car\n",
      "\n",
      "0: 416x320 (no detections), 32.8ms\n",
      "Speed: 0.0ms preprocess, 32.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Confianza ---> 0.21\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "\n",
      "0: 416x352 (no detections), 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.19\n",
      "Clase --> car\n",
      "\n",
      "0: 416x352 1 matriculas, 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 56.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "\n",
      "0: 416x160 (no detections), 27.8ms\n",
      "Speed: 1.0ms preprocess, 27.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 57.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.9ms\n",
      "\n",
      "0: 416x160 (no detections), 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.2ms\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 28.6ms\n",
      "Speed: 0.0ms preprocess, 28.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.1ms\n",
      "\n",
      "0: 416x160 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 61.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 46.6ms\n",
      "\n",
      "0: 416x160 (no detections), 24.2ms\n",
      "Speed: 1.0ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 27.8ms\n",
      "Speed: 0.0ms preprocess, 27.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.23\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 44.2ms\n",
      "\n",
      "0: 416x160 (no detections), 26.0ms\n",
      "Speed: 0.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 192x416 (no detections), 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 3 matriculass, 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 44.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 45.1ms\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.8ms\n",
      "Speed: 0.0ms preprocess, 25.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 192x416 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "Confianza ---> 0.67\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 1 matriculas, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.2\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 48.1ms\n",
      "\n",
      "0: 416x160 (no detections), 23.2ms\n",
      "Speed: 0.0ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "\n",
      "0: 224x416 1 matriculas, 43.1ms\n",
      "Speed: 0.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Confianza ---> 0.15\n",
      "Clase --> person\n",
      "\n",
      "0: 320x416 1 matriculas, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 35.6ms\n",
      "Speed: 0.0ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 48.6ms\n",
      "\n",
      "0: 288x416 1 matriculas, 30.4ms\n",
      "Speed: 1.0ms preprocess, 30.4ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 23.2ms\n",
      "Speed: 0.0ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 224x416 (no detections), 29.9ms\n",
      "Speed: 1.0ms preprocess, 29.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 416x160 (no detections), 26.2ms\n",
      "Speed: 0.0ms preprocess, 26.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 47.0ms\n",
      "\n",
      "0: 416x160 (no detections), 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 192x416 1 matriculas, 24.8ms\n",
      "Speed: 1.0ms preprocess, 24.8ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.13\n",
      "Clase --> person\n",
      "\n",
      "0: 416x128 (no detections), 23.4ms\n",
      "Speed: 1.0ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 46.1ms\n",
      "\n",
      "0: 416x160 (no detections), 26.9ms\n",
      "Speed: 1.0ms preprocess, 26.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 288x416 1 matriculas, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.18\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "\n",
      "0: 224x416 (no detections), 28.2ms\n",
      "Speed: 0.0ms preprocess, 28.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 46.2ms\n",
      "\n",
      "0: 416x128 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 25.1ms\n",
      "Speed: 1.0ms preprocess, 25.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 224x416 (no detections), 44.6ms\n",
      "Speed: 0.0ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 288x416 1 matriculas, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.17\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.6ms\n",
      "\n",
      "0: 416x128 (no detections), 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 416x160 (no detections), 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.5ms\n",
      "\n",
      "0: 416x160 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 46.7ms\n",
      "\n",
      "0: 416x160 (no detections), 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "\n",
      "0: 224x416 (no detections), 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "Speed: 1.5ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "\n",
    "result_default = YOLO('yolo11n.pt')\n",
    "result_car_plates = YOLO('runs/detect/train2/weights/best.pt')\n",
    "\n",
    "vid = cv2.VideoCapture('C0142.MP4')\n",
    "\n",
    "frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "out = cv2.VideoWriter('output_detected.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "classNames = [\"person\", \"\", \"car\", \"motorbike\", \"\", \"bus\"]\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "scale_factor = 4\n",
    "\n",
    "while(True):      \n",
    "    ret, img = vid.read()\n",
    "\n",
    "    if ret:  \n",
    "        results = result_default.track(img, stream=True, device='cpu', classes=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                clase = classNames[cls]\n",
    "\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "\n",
    "                x1_coche, y1_coche, x2_coche, y2_coche = box.xyxy[0]\n",
    "                x1_coche, y1_coche, x2_coche, y2_coche = int(x1_coche), int(y1_coche), int(x2_coche), int(y2_coche)\n",
    "\n",
    "                width_coche = x2_coche - x1_coche\n",
    "                height_coche = y2_coche - y1_coche\n",
    "\n",
    "                new_width = int(width_coche * scale_factor)\n",
    "                new_height = int(height_coche * scale_factor)\n",
    "\n",
    "                new_x1 = max(0, x1_coche - (new_width - width_coche) // 2)\n",
    "                new_y1 = max(0, y1_coche - (new_height - height_coche) // 2)\n",
    "                new_x2 = min(img.shape[1], new_x1 + new_width)\n",
    "                new_y2 = min(img.shape[0], new_y1 + new_height)\n",
    "\n",
    "                cropImg = img[new_y1:new_y2, new_x1:new_x2]\n",
    "\n",
    "                matricula = result_car_plates.track(cropImg, stream=True, device='cpu')\n",
    "\n",
    "                best_confidence = 0\n",
    "                best_box = None\n",
    "\n",
    "                for p in matricula:\n",
    "                    boxes_matricula = p.boxes\n",
    "\n",
    "                    for box in boxes_matricula:\n",
    "                        x1_matricula, y1_matricula, x2_matricula, y2_matricula = box.xyxy[0]\n",
    "                        x1_matricula, y1_matricula, x2_matricula, y2_matricula = int(x1_matricula), int(y1_matricula), int(x2_matricula), int(y2_matricula)\n",
    "\n",
    "                        confidence_mat = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                        if confidence_mat > best_confidence:\n",
    "                            best_confidence = confidence_mat\n",
    "                            best_box = (x1_matricula, y1_matricula, x2_matricula, y2_matricula)\n",
    "\n",
    "                if best_box is not None and best_confidence >= 0.15:\n",
    "                    x1_matricula, y1_matricula, x2_matricula, y2_matricula = best_box\n",
    "                    cv2.rectangle(img, (new_x1 + x1_matricula, new_y1 + y1_matricula), \n",
    "                                    (new_x1 + x2_matricula, new_y1 + y2_matricula), (0, 0, 255), 3)\n",
    "                    cv2.putText(img, f\"matricula conf: [{best_confidence:.2f}]\", (new_x1 + x1_matricula, new_y1 + y1_matricula), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "                print(\"Confianza --->\", confidence)\n",
    "\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255 * 2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255 * 2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                cv2.rectangle(img, (x1_coche, y1_coche), (x2_coche, y2_coche), (R, G, B), 3)\n",
    "                cv2.putText(img, f\"[{track_id}] {classNames[cls]} conf: [{confidence}]\", (x1_coche, y1_coche - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, B), 2)\n",
    "        \n",
    "        out.write(img)\n",
    "        cv2.imshow('Vid', img)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos preentrenados, visualizando con las utilidades de ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:184 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:96 [backend fallback]\nAutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:91 [backend fallback]\nTracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastXPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:41 [kernel]\nAutocastMPS: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#model = YOLO('yolo11n-pose.pt')  #Pose\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Para un vídeo \u001b[39;00m\n\u001b[0;32m      7\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTGC23_PdH_C0056cut.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\ultralytics\\engine\\model.py:176\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    149\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    150\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\ultralytics\\engine\\model.py:554\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_postprocess_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\ultralytics\\models\\yolo\\segment\\predict.py:30\u001b[0m, in \u001b[0;36mSegmentationPredictor.postprocess\u001b[1;34m(self, preds, img, orig_imgs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds, img, orig_imgs):\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies non-max suppression and processes detections for each image in an input batch.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43magnostic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_imgs, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# input images are a torch.Tensor, not a list\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         orig_imgs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\ultralytics\\utils\\ops.py:292\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[1;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m x[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m c  \u001b[38;5;66;03m# boxes (offset by class)\u001b[39;00m\n\u001b[1;32m--> 292\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_thres\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# NMS\u001b[39;00m\n\u001b[0;32m    293\u001b[0m i \u001b[38;5;241m=\u001b[39m i[:max_det]  \u001b[38;5;66;03m# limit detections\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# # Experimental\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;66;03m# merge = False  # use merge-NMS\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m#     if redundant:\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;66;03m#         i = i[iou.sum(1) > 1]  # require redundancy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m     40\u001b[0m _assert_has_ops()\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\P4\\lib\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:184 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:96 [backend fallback]\nAutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:91 [backend fallback]\nTracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastXPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:41 [kernel]\nAutocastMPS: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "#model = YOLO('yolo11n.pt') #Contenedores\n",
    "model = YOLO('yolo11n-seg.pt') #Máscaras\n",
    "#model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model(filename, show=True)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolo11, modelo nano. Visualización propia con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Detecta en la imagen\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 64.9ms\n",
      "Speed: 3.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 49.9ms\n",
      "Speed: 1.5ms preprocess, 49.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 49.9ms\n",
      "Speed: 2.0ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.7ms\n",
      "Speed: 1.5ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 49.1ms\n",
      "Speed: 1.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 50.5ms\n",
      "Speed: 0.5ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 49.8ms\n",
      "Speed: 2.0ms preprocess, 49.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.3ms\n",
      "Speed: 1.0ms preprocess, 44.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.3ms\n",
      "Speed: 1.0ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.9ms\n",
      "Speed: 1.0ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 1.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 0.0ms preprocess, 42.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 2.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.2ms\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.3ms\n",
      "Speed: 1.0ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.2ms\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.0ms\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.4ms\n",
      "Speed: 2.0ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.8ms\n",
      "Speed: 1.5ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.4ms\n",
      "Speed: 2.0ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.2ms\n",
      "Speed: 0.5ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.9ms\n",
      "Speed: 2.0ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.9ms\n",
      "Speed: 2.5ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 2.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.4ms\n",
      "Speed: 1.0ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.0ms\n",
      "Speed: 2.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.8ms\n",
      "Speed: 1.5ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.8ms\n",
      "Speed: 1.0ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 1.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.9ms\n",
      "Speed: 1.0ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.4ms\n",
      "Speed: 1.0ms preprocess, 43.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.9ms\n",
      "Speed: 1.5ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.1ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.3ms\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 2.4ms preprocess, 43.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\"]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "track_history = defaultdict(lambda: [])\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Seguimiento, con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes = [0,1,2])\n",
    "\n",
    "        if 0:\n",
    "            if results is not None:\n",
    "                print(results[0])\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "                annotated_frame = results[0].plot()\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "                cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "                #Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, track_id + ' ' + classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intregración con seguimiento (tracking)\n",
    "!!!!!!!!!Nota: he tenido que bajar a la versión de python 3.9.5 e instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 43.1ms\n",
      "video 1/1 (frame 2/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 45.1ms\n",
      "video 1/1 (frame 3/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 43.8ms\n",
      "video 1/1 (frame 4/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 44.1ms\n",
      "video 1/1 (frame 5/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 44.2ms\n",
      "video 1/1 (frame 6/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 41.7ms\n",
      "video 1/1 (frame 7/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 43.3ms\n",
      "video 1/1 (frame 8/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 40.9ms\n",
      "video 1/1 (frame 9/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 41.6ms\n",
      "video 1/1 (frame 10/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 44.1ms\n",
      "video 1/1 (frame 11/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 5 persons, 1 bird, 49.1ms\n",
      "video 1/1 (frame 12/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 5 persons, 1 bird, 42.6ms\n",
      "video 1/1 (frame 13/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 42.6ms\n",
      "video 1/1 (frame 14/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 44.3ms\n",
      "video 1/1 (frame 15/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 43.1ms\n",
      "video 1/1 (frame 16/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 42.1ms\n",
      "video 1/1 (frame 17/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.6ms\n",
      "video 1/1 (frame 18/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.5ms\n",
      "video 1/1 (frame 19/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.6ms\n",
      "video 1/1 (frame 20/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.6ms\n",
      "video 1/1 (frame 21/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.3ms\n",
      "video 1/1 (frame 22/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.8ms\n",
      "video 1/1 (frame 23/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.4ms\n",
      "video 1/1 (frame 24/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 46.5ms\n",
      "video 1/1 (frame 25/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.8ms\n",
      "video 1/1 (frame 26/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 27/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.1ms\n",
      "video 1/1 (frame 28/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 29/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.1ms\n",
      "video 1/1 (frame 30/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.6ms\n",
      "video 1/1 (frame 31/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.2ms\n",
      "video 1/1 (frame 32/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 53.1ms\n",
      "video 1/1 (frame 33/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.3ms\n",
      "video 1/1 (frame 34/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.6ms\n",
      "video 1/1 (frame 35/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 39.8ms\n",
      "video 1/1 (frame 36/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.3ms\n",
      "video 1/1 (frame 37/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 38/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 39.1ms\n",
      "video 1/1 (frame 39/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.1ms\n",
      "video 1/1 (frame 40/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.3ms\n",
      "video 1/1 (frame 41/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 39.6ms\n",
      "video 1/1 (frame 42/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 38.1ms\n",
      "video 1/1 (frame 43/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.1ms\n",
      "video 1/1 (frame 44/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.2ms\n",
      "video 1/1 (frame 45/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.6ms\n",
      "video 1/1 (frame 46/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.6ms\n",
      "video 1/1 (frame 47/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.1ms\n",
      "video 1/1 (frame 48/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.9ms\n",
      "video 1/1 (frame 49/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 39.1ms\n",
      "video 1/1 (frame 50/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.2ms\n",
      "video 1/1 (frame 51/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 52/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.7ms\n",
      "video 1/1 (frame 53/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 54/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.6ms\n",
      "video 1/1 (frame 55/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.4ms\n",
      "video 1/1 (frame 56/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.1ms\n",
      "video 1/1 (frame 57/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.6ms\n",
      "video 1/1 (frame 58/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.2ms\n",
      "video 1/1 (frame 59/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.7ms\n",
      "video 1/1 (frame 60/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.1ms\n",
      "video 1/1 (frame 61/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.2ms\n",
      "video 1/1 (frame 62/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.2ms\n",
      "video 1/1 (frame 63/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 64/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.0ms\n",
      "video 1/1 (frame 65/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.6ms\n",
      "video 1/1 (frame 66/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 39.1ms\n",
      "video 1/1 (frame 67/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.2ms\n",
      "video 1/1 (frame 68/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 69/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 39.6ms\n",
      "video 1/1 (frame 70/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.2ms\n",
      "video 1/1 (frame 71/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.0ms\n",
      "video 1/1 (frame 72/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 47.1ms\n",
      "video 1/1 (frame 73/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 47.1ms\n",
      "video 1/1 (frame 74/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.3ms\n",
      "video 1/1 (frame 75/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.0ms\n",
      "video 1/1 (frame 76/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.7ms\n",
      "video 1/1 (frame 77/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.2ms\n",
      "video 1/1 (frame 78/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.7ms\n",
      "video 1/1 (frame 79/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 80/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 81/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.6ms\n",
      "video 1/1 (frame 82/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.7ms\n",
      "video 1/1 (frame 83/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.1ms\n",
      "video 1/1 (frame 84/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.1ms\n",
      "video 1/1 (frame 85/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.5ms\n",
      "video 1/1 (frame 86/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.1ms\n",
      "video 1/1 (frame 87/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 88/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.1ms\n",
      "video 1/1 (frame 89/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.6ms\n",
      "video 1/1 (frame 90/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.6ms\n",
      "video 1/1 (frame 91/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.1ms\n",
      "video 1/1 (frame 92/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.3ms\n",
      "video 1/1 (frame 93/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.6ms\n",
      "video 1/1 (frame 94/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.0ms\n",
      "video 1/1 (frame 95/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.4ms\n",
      "video 1/1 (frame 96/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.3ms\n",
      "video 1/1 (frame 97/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 98/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.7ms\n",
      "video 1/1 (frame 99/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.4ms\n",
      "video 1/1 (frame 100/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 101/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.1ms\n",
      "video 1/1 (frame 102/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.0ms\n",
      "video 1/1 (frame 103/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.1ms\n",
      "video 1/1 (frame 104/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 39.4ms\n",
      "video 1/1 (frame 105/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 106/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.2ms\n",
      "video 1/1 (frame 107/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.9ms\n",
      "video 1/1 (frame 108/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 46.3ms\n",
      "video 1/1 (frame 109/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.5ms\n",
      "video 1/1 (frame 110/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.1ms\n",
      "video 1/1 (frame 111/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.0ms\n",
      "video 1/1 (frame 112/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.6ms\n",
      "video 1/1 (frame 113/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 46.1ms\n",
      "video 1/1 (frame 114/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 49.7ms\n",
      "video 1/1 (frame 115/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.6ms\n",
      "video 1/1 (frame 116/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.1ms\n",
      "video 1/1 (frame 117/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 47.2ms\n",
      "video 1/1 (frame 118/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 49.4ms\n",
      "video 1/1 (frame 119/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 47.1ms\n",
      "video 1/1 (frame 120/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.9ms\n",
      "video 1/1 (frame 121/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.6ms\n",
      "video 1/1 (frame 122/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.4ms\n",
      "video 1/1 (frame 123/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 46.2ms\n",
      "video 1/1 (frame 124/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 48.0ms\n",
      "video 1/1 (frame 125/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 57.6ms\n",
      "video 1/1 (frame 126/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 127/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.1ms\n",
      "video 1/1 (frame 128/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.6ms\n",
      "video 1/1 (frame 129/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.2ms\n",
      "video 1/1 (frame 130/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.4ms\n",
      "video 1/1 (frame 131/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.3ms\n",
      "video 1/1 (frame 132/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.7ms\n",
      "video 1/1 (frame 133/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 51.1ms\n",
      "video 1/1 (frame 134/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 47.8ms\n",
      "video 1/1 (frame 135/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.3ms\n",
      "video 1/1 (frame 136/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.6ms\n",
      "video 1/1 (frame 137/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 138/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.9ms\n",
      "video 1/1 (frame 139/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.5ms\n",
      "video 1/1 (frame 140/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 46.1ms\n",
      "video 1/1 (frame 141/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.9ms\n",
      "video 1/1 (frame 142/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 46.0ms\n",
      "video 1/1 (frame 143/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.2ms\n",
      "video 1/1 (frame 144/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.6ms\n",
      "video 1/1 (frame 145/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.4ms\n",
      "video 1/1 (frame 146/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 147/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.6ms\n",
      "video 1/1 (frame 148/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 149/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 48.6ms\n",
      "video 1/1 (frame 150/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.3ms\n",
      "video 1/1 (frame 151/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.7ms\n",
      "video 1/1 (frame 152/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 153/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 154/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.6ms\n",
      "video 1/1 (frame 155/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 39.5ms\n",
      "video 1/1 (frame 156/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 157/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.6ms\n",
      "video 1/1 (frame 158/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.2ms\n",
      "video 1/1 (frame 159/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.6ms\n",
      "video 1/1 (frame 160/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.8ms\n",
      "video 1/1 (frame 161/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.6ms\n",
      "video 1/1 (frame 162/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 163/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.6ms\n",
      "video 1/1 (frame 164/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.8ms\n",
      "video 1/1 (frame 165/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.0ms\n",
      "video 1/1 (frame 166/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.3ms\n",
      "video 1/1 (frame 167/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.6ms\n",
      "video 1/1 (frame 168/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.4ms\n",
      "video 1/1 (frame 169/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.7ms\n",
      "video 1/1 (frame 170/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.6ms\n",
      "video 1/1 (frame 171/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 172/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.3ms\n",
      "video 1/1 (frame 173/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.1ms\n",
      "video 1/1 (frame 174/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.5ms\n",
      "video 1/1 (frame 175/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.7ms\n",
      "video 1/1 (frame 176/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.1ms\n",
      "video 1/1 (frame 177/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 178/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.8ms\n",
      "video 1/1 (frame 179/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.1ms\n",
      "video 1/1 (frame 180/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.1ms\n",
      "video 1/1 (frame 181/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.3ms\n",
      "video 1/1 (frame 182/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.2ms\n",
      "video 1/1 (frame 183/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.2ms\n",
      "video 1/1 (frame 184/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.4ms\n",
      "video 1/1 (frame 185/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.2ms\n",
      "video 1/1 (frame 186/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 187/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.6ms\n",
      "video 1/1 (frame 188/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.6ms\n",
      "video 1/1 (frame 189/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.0ms\n",
      "video 1/1 (frame 190/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 191/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.2ms\n",
      "video 1/1 (frame 192/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 193/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.1ms\n",
      "video 1/1 (frame 194/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.3ms\n",
      "video 1/1 (frame 195/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 horse, 44.5ms\n",
      "video 1/1 (frame 196/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 horse, 41.8ms\n",
      "video 1/1 (frame 197/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.6ms\n",
      "video 1/1 (frame 198/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 39.1ms\n",
      "video 1/1 (frame 199/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.2ms\n",
      "video 1/1 (frame 200/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.1ms\n",
      "video 1/1 (frame 201/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 horse, 43.2ms\n",
      "video 1/1 (frame 202/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.6ms\n",
      "video 1/1 (frame 203/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.0ms\n",
      "video 1/1 (frame 204/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.7ms\n",
      "video 1/1 (frame 205/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 206/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 46.1ms\n",
      "video 1/1 (frame 207/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.4ms\n",
      "video 1/1 (frame 208/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.6ms\n",
      "video 1/1 (frame 209/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.6ms\n",
      "video 1/1 (frame 210/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.1ms\n",
      "video 1/1 (frame 211/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.9ms\n",
      "video 1/1 (frame 212/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.3ms\n",
      "video 1/1 (frame 213/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.8ms\n",
      "video 1/1 (frame 214/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.7ms\n",
      "video 1/1 (frame 215/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.5ms\n",
      "video 1/1 (frame 216/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.8ms\n",
      "video 1/1 (frame 217/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 38.6ms\n",
      "video 1/1 (frame 218/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 219/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.6ms\n",
      "video 1/1 (frame 220/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.0ms\n",
      "video 1/1 (frame 221/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 222/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.1ms\n",
      "video 1/1 (frame 223/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.2ms\n",
      "video 1/1 (frame 224/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.1ms\n",
      "video 1/1 (frame 225/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.5ms\n",
      "video 1/1 (frame 226/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.3ms\n",
      "video 1/1 (frame 227/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.1ms\n",
      "video 1/1 (frame 228/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 47.5ms\n",
      "video 1/1 (frame 229/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.1ms\n",
      "video 1/1 (frame 230/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 46.3ms\n",
      "video 1/1 (frame 231/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 232/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.2ms\n",
      "video 1/1 (frame 233/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.2ms\n",
      "video 1/1 (frame 234/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.6ms\n",
      "video 1/1 (frame 235/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.1ms\n",
      "video 1/1 (frame 236/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 237/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 47.6ms\n",
      "video 1/1 (frame 238/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 46.6ms\n",
      "video 1/1 (frame 239/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.5ms\n",
      "video 1/1 (frame 240/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.2ms\n",
      "video 1/1 (frame 241/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.8ms\n",
      "video 1/1 (frame 242/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 243/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.3ms\n",
      "video 1/1 (frame 244/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 245/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.9ms\n",
      "video 1/1 (frame 246/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 44.2ms\n",
      "video 1/1 (frame 247/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.7ms\n",
      "video 1/1 (frame 248/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 42.4ms\n",
      "video 1/1 (frame 249/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 42.6ms\n",
      "video 1/1 (frame 250/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.8ms\n",
      "video 1/1 (frame 251/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 42.6ms\n",
      "video 1/1 (frame 252/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.1ms\n",
      "video 1/1 (frame 253/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.1ms\n",
      "video 1/1 (frame 254/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 255/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.7ms\n",
      "video 1/1 (frame 256/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 39.1ms\n",
      "video 1/1 (frame 257/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 258/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 259/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.7ms\n",
      "video 1/1 (frame 260/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.6ms\n",
      "video 1/1 (frame 261/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 38.4ms\n",
      "video 1/1 (frame 262/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 41.9ms\n",
      "video 1/1 (frame 263/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 54.5ms\n",
      "video 1/1 (frame 264/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 41.1ms\n",
      "video 1/1 (frame 265/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 41.1ms\n",
      "video 1/1 (frame 266/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 42.8ms\n",
      "video 1/1 (frame 267/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 41.6ms\n",
      "video 1/1 (frame 268/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 39.6ms\n",
      "video 1/1 (frame 269/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 41.6ms\n",
      "video 1/1 (frame 270/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.2ms\n",
      "video 1/1 (frame 271/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 44.1ms\n",
      "video 1/1 (frame 272/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.8ms\n",
      "video 1/1 (frame 273/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 45.1ms\n",
      "video 1/1 (frame 274/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.3ms\n",
      "video 1/1 (frame 275/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 40.6ms\n",
      "video 1/1 (frame 276/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.2ms\n",
      "video 1/1 (frame 277/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 40.1ms\n",
      "video 1/1 (frame 278/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 44.1ms\n",
      "video 1/1 (frame 279/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 39.6ms\n",
      "video 1/1 (frame 280/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 44.0ms\n",
      "video 1/1 (frame 281/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 41.1ms\n",
      "video 1/1 (frame 282/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 42.5ms\n",
      "video 1/1 (frame 283/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 42.1ms\n",
      "video 1/1 (frame 284/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 43.5ms\n",
      "video 1/1 (frame 285/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 42.1ms\n",
      "video 1/1 (frame 286/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 41.7ms\n",
      "video 1/1 (frame 287/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 41.1ms\n",
      "video 1/1 (frame 288/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 42.0ms\n",
      "video 1/1 (frame 289/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 43.5ms\n",
      "video 1/1 (frame 290/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 41.1ms\n",
      "video 1/1 (frame 291/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 45.2ms\n",
      "video 1/1 (frame 292/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 42.8ms\n",
      "video 1/1 (frame 293/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 39.0ms\n",
      "video 1/1 (frame 294/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 40.7ms\n",
      "video 1/1 (frame 295/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 42.3ms\n",
      "video 1/1 (frame 296/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 40.6ms\n",
      "video 1/1 (frame 297/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 40.6ms\n",
      "video 1/1 (frame 298/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 39.9ms\n",
      "video 1/1 (frame 299/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 39.1ms\n",
      "video 1/1 (frame 300/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 motorcycle, 41.1ms\n",
      "video 1/1 (frame 301/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 37.2ms\n",
      "video 1/1 (frame 302/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 39.7ms\n",
      "video 1/1 (frame 303/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 38.6ms\n",
      "video 1/1 (frame 304/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 motorcycle, 40.5ms\n",
      "video 1/1 (frame 305/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 motorcycle, 41.0ms\n",
      "video 1/1 (frame 306/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 41.1ms\n",
      "video 1/1 (frame 307/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 44.6ms\n",
      "video 1/1 (frame 308/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 40.1ms\n",
      "video 1/1 (frame 309/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 42.2ms\n",
      "video 1/1 (frame 310/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 42.1ms\n",
      "video 1/1 (frame 311/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 40.4ms\n",
      "video 1/1 (frame 312/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 40.0ms\n",
      "video 1/1 (frame 313/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 44.6ms\n",
      "video 1/1 (frame 314/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 43.3ms\n",
      "video 1/1 (frame 315/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 39.8ms\n",
      "video 1/1 (frame 316/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 bicycle, 41.1ms\n",
      "video 1/1 (frame 317/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.9ms\n",
      "video 1/1 (frame 318/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 41.7ms\n",
      "video 1/1 (frame 319/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 320/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 321/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 322/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.8ms\n",
      "video 1/1 (frame 323/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.3ms\n",
      "video 1/1 (frame 324/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.7ms\n",
      "video 1/1 (frame 325/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.8ms\n",
      "video 1/1 (frame 326/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 41.8ms\n",
      "video 1/1 (frame 327/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.1ms\n",
      "video 1/1 (frame 328/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.1ms\n",
      "video 1/1 (frame 329/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.3ms\n",
      "video 1/1 (frame 330/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.9ms\n",
      "video 1/1 (frame 331/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.0ms\n",
      "video 1/1 (frame 332/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.7ms\n",
      "video 1/1 (frame 333/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.6ms\n",
      "video 1/1 (frame 334/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.2ms\n",
      "video 1/1 (frame 335/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 336/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.4ms\n",
      "video 1/1 (frame 337/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 338/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.9ms\n",
      "video 1/1 (frame 339/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 45.2ms\n",
      "video 1/1 (frame 340/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.2ms\n",
      "video 1/1 (frame 341/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 43.7ms\n",
      "video 1/1 (frame 342/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.4ms\n",
      "video 1/1 (frame 343/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 41.3ms\n",
      "video 1/1 (frame 344/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 45.2ms\n",
      "video 1/1 (frame 345/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 43.2ms\n",
      "video 1/1 (frame 346/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 40.7ms\n",
      "video 1/1 (frame 347/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 44.2ms\n",
      "video 1/1 (frame 348/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 44.1ms\n",
      "video 1/1 (frame 349/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 44.2ms\n",
      "video 1/1 (frame 350/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 39.2ms\n",
      "video 1/1 (frame 351/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 39.6ms\n",
      "video 1/1 (frame 352/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.6ms\n",
      "video 1/1 (frame 353/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.1ms\n",
      "video 1/1 (frame 354/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.8ms\n",
      "video 1/1 (frame 355/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.6ms\n",
      "video 1/1 (frame 356/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.4ms\n",
      "video 1/1 (frame 357/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.6ms\n",
      "video 1/1 (frame 358/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 359/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 38.8ms\n",
      "video 1/1 (frame 360/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.7ms\n",
      "video 1/1 (frame 361/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.1ms\n",
      "video 1/1 (frame 362/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.1ms\n",
      "video 1/1 (frame 363/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.4ms\n",
      "video 1/1 (frame 364/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.3ms\n",
      "video 1/1 (frame 365/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.9ms\n",
      "video 1/1 (frame 366/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 41.2ms\n",
      "video 1/1 (frame 367/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.5ms\n",
      "video 1/1 (frame 368/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.8ms\n",
      "video 1/1 (frame 369/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.0ms\n",
      "video 1/1 (frame 370/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.9ms\n",
      "video 1/1 (frame 371/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.7ms\n",
      "video 1/1 (frame 372/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 44.7ms\n",
      "video 1/1 (frame 373/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 42.9ms\n",
      "video 1/1 (frame 374/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 42.0ms\n",
      "video 1/1 (frame 375/375) c:\\Users\\Mauro Gmez\\VC\\VC-P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 44.5ms\n",
      "Speed: 1.3ms preprocess, 43.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolov11n-seg.pt') #Máscaras\n",
    "#model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model.track(source=filename, show=True)  # BoT-SORT tracker (por defecto)\n",
    "#results = model.track(source=filename, show=True, tracker=\"bytetrack.yaml\")  # ByteTrack tracker\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afr', 'amh', 'ara', 'asm', 'aze', 'aze_cyrl', 'bel', 'ben', 'bod', 'bos', 'bre', 'bul', 'cat', 'ceb', 'ces', 'chi_sim', 'chi_sim_vert', 'chi_tra', 'chi_tra_vert', 'chr', 'cos', 'cym', 'dan', 'deu', 'deu_latf', 'div', 'dzo', 'ell', 'eng', 'enm', 'epo', 'equ', 'est', 'eus', 'fao', 'fas', 'fil', 'fin', 'fra', 'frm', 'fry', 'gla', 'gle', 'glg', 'grc', 'guj', 'hat', 'heb', 'hin', 'hrv', 'hun', 'hye', 'iku', 'ind', 'isl', 'ita', 'ita_old', 'jav', 'jpn', 'jpn_vert', 'kan', 'kat', 'kat_old', 'kaz', 'khm', 'kir', 'kmr', 'kor', 'lao', 'lat', 'lav', 'lit', 'ltz', 'mal', 'mar', 'mkd', 'mlt', 'mon', 'mri', 'msa', 'mya', 'nep', 'nld', 'nor', 'oci', 'ori', 'osd', 'pan', 'pol', 'por', 'pus', 'que', 'ron', 'rus', 'san', 'sin', 'slk', 'slv', 'snd', 'spa', 'spa_old', 'sqi', 'srp', 'srp_latn', 'sun', 'swa', 'swe', 'syr', 'tam', 'tat', 'tel', 'tgk', 'tha', 'tir', 'ton', 'tur', 'uig', 'ukr', 'urd', 'uzb', 'uzb_cyrl', 'vie', 'yid', 'yor']\n",
      "Hasta el infinito y mas alla\n",
      "\n",
      "Texto: Hasta (96.00%)\n",
      "Contenedor: (57, 95, 176, 130)\n",
      "Texto: el (93.00%)\n",
      "Contenedor: (194, 95, 226, 130)\n",
      "Texto: infinito (91.00%)\n",
      "Contenedor: (246, 95, 380, 130)\n",
      "Texto: y (92.00%)\n",
      "Contenedor: (408, 104, 418, 140)\n",
      "Texto: mas (96.00%)\n",
      "Contenedor: (435, 94, 521, 130)\n",
      "Texto: alla (96.00%)\n",
      "Contenedor: (538, 94, 609, 130)\n"
     ]
    }
   ],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'D:/OneDrive/Escritorio/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('ocr_test.tif') \n",
    "\n",
    "if img is not None:\n",
    "    #Convierte a RGB antes de procesar\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Texto localizado\n",
    "    print(pytesseract.image_to_string(img))\n",
    "\n",
    "    #Texto y localización en imagen de cada palabra\n",
    "    d = pytesseract.image_to_data(img_rgb, output_type=Output.DICT)\n",
    "\n",
    "    n_boxes = len(d['text'])\n",
    "    for i in range(n_boxes):\n",
    "        #Nivel de confianza\n",
    "        if int(d['conf'][i]) > 60:\n",
    "            text = d['text'][i]\n",
    "            conf = d['conf'][i]\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            print(f'Texto: {text} ({conf:.2f}%)\\nContenedor: {x,y,x+w,y+h}')\n",
    "\n",
    "    cv2.imshow('img', img_rgb)\n",
    "    cv2.waitKey(-1)\n",
    "\n",
    "   \n",
    "\n",
    "else:\n",
    "    print('Error de imagen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easyocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01measyocr\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Carga del modelo de lengua\u001b[39;00m\n\u001b[0;32m      4\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'easyocr'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "res = reader.readtext('ocr_test.tif')\n",
    "\n",
    "for (bbox, text, prob) in res:\n",
    "    # Coordenadas en orden \n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    print(f'\\nTexto: {text}\\nProbabilidad: {prob:.2f}\\nContenedor: {tuple(map(int, top_left)),tuple(map(int, bottom_right))}')\n",
    "\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
